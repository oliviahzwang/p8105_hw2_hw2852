P8105 Data Science I Homework 2
================
Olivia Wang (hw2852)
2022-10-05

# Problem 1

In preparation for the problems below, we will load in the following
libraries: `tidyverse`, `dplyr`, and `readxl`.

``` r
library(tidyverse)
```

    ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──
    ## ✔ ggplot2 3.3.6      ✔ purrr   0.3.4 
    ## ✔ tibble  3.1.8      ✔ dplyr   1.0.10
    ## ✔ tidyr   1.2.0      ✔ stringr 1.4.1 
    ## ✔ readr   2.1.2      ✔ forcats 0.5.2 
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()

``` r
library(dplyr)
library(readxl)
```

## 1.1 Transit Data: Read, Clean, Select, Mutate

We will begin by importing and cleaning the CSV file containing the NYC
Transit data. This process involves data import, cleaning variable
names, and retaining prescribed columns needed for further analysis. The
`entry` variable in the data set will be converted from a character to
logical vector, and `Route` columns 8 through 11 will be converted from
a numeric to character variable to achieve consistency with Routes 1
through 7.

``` r
transit_data = 
  read_csv("./NYC_Transit_Subway_Entrance_And_Exit_Data.csv", 
             col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) %>% 
  janitor::clean_names(.) %>% 
  select(line, station_name, station_latitude, station_longitude, starts_with("route"), entry, exit_only, vending, entrance_type, ada) %>% 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

These data are not entirely tidy as they are shown, since there are
additional improvements that can be made. For example, we may apply the
`pivot_longer` function to convert the data from wide to long format by
collapsing the existing variables starting with `route`. We can then
create new `route number` and `route` variables, populated with relevant
information.

## 1.2 Analyzing Transit Data

### Unique Stations

Next, Using the `distint` function, we can identify the unique
combinations of `station_name` and `line` variable values. The number of
rows generated in the output would be the number of *unique* stations in
the data set.

``` r
transit_data %>% 
  select(station_name, line) %>% 
  distinct
```

    ## # A tibble: 465 × 2
    ##    station_name             line    
    ##    <chr>                    <chr>   
    ##  1 25th St                  4 Avenue
    ##  2 36th St                  4 Avenue
    ##  3 45th St                  4 Avenue
    ##  4 53rd St                  4 Avenue
    ##  5 59th St                  4 Avenue
    ##  6 77th St                  4 Avenue
    ##  7 86th St                  4 Avenue
    ##  8 95th St                  4 Avenue
    ##  9 9th St                   4 Avenue
    ## 10 Atlantic Av-Barclays Ctr 4 Avenue
    ## # … with 455 more rows

There are **465** unique stations in the data set.

### Unique ADA-Compliant Stations

Using a similar approach applied to determining the number of distinct
stations, we can apply the `distinct` function again to determine the
number of *unique* ADA-compliant stations. We first begin by filtering
the `transit_data` data frame to only include ADA-compliant stations.
The number of rows generated in the output is the number of *unique*
ADA-compliant stations in the data set.

``` r
transit_data %>% 
  filter(ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

    ## # A tibble: 84 × 2
    ##    station_name                   line           
    ##    <chr>                          <chr>          
    ##  1 Atlantic Av-Barclays Ctr       4 Avenue       
    ##  2 DeKalb Av                      4 Avenue       
    ##  3 Pacific St                     4 Avenue       
    ##  4 Grand Central                  42nd St Shuttle
    ##  5 34th St                        6 Avenue       
    ##  6 47-50th Sts Rockefeller Center 6 Avenue       
    ##  7 Church Av                      6 Avenue       
    ##  8 21st St                        63rd Street    
    ##  9 Lexington Av                   63rd Street    
    ## 10 Roosevelt Island               63rd Street    
    ## # … with 74 more rows

There are **84** unique ADA-compliant stations in the data set.

### Proportion of Entrances/Exits Without Vending that Allow Entrance

To determine the proportion of entrances and exits without vending that
allow entrance, we can first apply the `filter` function to exclude
station entrances without vending. Next, we can take the mean of the
`entry` variable to generate the desired proportion. Recall that in part
1.1, the `entry` variable was converted from a character to logical
variable. R is able to coerce logical to numeric variables for these
types of arithmetic calculations.

``` r
transit_data %>% 
  filter(vending == "NO") %>% 
  pull(entry) %>% 
  mean
```

    ## [1] 0.3770492

About **37.7%** of station entrances/exits without vending allow
entrance.

### Unique Stations Serving the A Train

We can first further tidy the data using the aforementioned method in
part 1.1, specifically using the `pivot_longer` function to convert the
`route` variable from wide to long format. We can apply similar
functions, specifically the `filter`, `select`, and `distinct` functions
to focus specifically on A train service, then identify unique stations.
The number of rows generated in the output is the number of unique
stations that serve the A train in the data set.

``` r
transit_data %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_number",
    values_to = "route") %>% 
  filter(route == "A") %>% 
  select(station_name, line) %>% 
  distinct
```

    ## # A tibble: 60 × 2
    ##    station_name                  line           
    ##    <chr>                         <chr>          
    ##  1 Times Square                  42nd St Shuttle
    ##  2 125th St                      8 Avenue       
    ##  3 145th St                      8 Avenue       
    ##  4 14th St                       8 Avenue       
    ##  5 168th St - Washington Heights 8 Avenue       
    ##  6 175th St                      8 Avenue       
    ##  7 181st St                      8 Avenue       
    ##  8 190th St                      8 Avenue       
    ##  9 34th St                       8 Avenue       
    ## 10 42nd St                       8 Avenue       
    ## # … with 50 more rows

There are **60** unique stations that serve the A train.

### Unique ADA-Compliant Stations Serving the A Train

Using the exact same methodology as above, we can determine the number
of unique ADA-compliant stations that serve the A train by filtering
both by A train service, as well as ADA-compliance. The number of rows
generated in the output is the number of unique ADA-compliant stations
that serve the A train in the data set.

``` r
transit_data %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_number",
    values_to = "route") %>% 
  filter(route == "A", ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

    ## # A tibble: 17 × 2
    ##    station_name                  line            
    ##    <chr>                         <chr>           
    ##  1 14th St                       8 Avenue        
    ##  2 168th St - Washington Heights 8 Avenue        
    ##  3 175th St                      8 Avenue        
    ##  4 34th St                       8 Avenue        
    ##  5 42nd St                       8 Avenue        
    ##  6 59th St                       8 Avenue        
    ##  7 Inwood - 207th St             8 Avenue        
    ##  8 West 4th St                   8 Avenue        
    ##  9 World Trade Center            8 Avenue        
    ## 10 Times Square-42nd St          Broadway        
    ## 11 59th St-Columbus Circle       Broadway-7th Ave
    ## 12 Times Square                  Broadway-7th Ave
    ## 13 8th Av                        Canarsie        
    ## 14 Franklin Av                   Franklin        
    ## 15 Euclid Av                     Fulton          
    ## 16 Franklin Av                   Fulton          
    ## 17 Howard Beach                  Rockaway

There are **17** unique ADA-compliant stations that serve the A train.

# Problem 2

## 2.1 Mr. Trash Wheel Data: Read, Clean, Select, Mutate

First, let us read and clean the Mr. Trash Wheel data set, contained
within the Trash Wheel Collection Data Excel spreadsheet. This process
involves data import using the `read_excel` function contained within
the `readxl` library, cleaning variable names, exclusion rows with
non-dumpster-specific data, and rounding of the `sports_balls` variable
to the nearest whole number. An additional variable `trash_program` was
created and added to the data frame in preparation for merging in
further steps of Problem 2.

``` r
mr_trash_wheel = 
  read_excel("Trash Wheel Collection Data.xlsx", col_names = TRUE, sheet = 1, skip = 1) %>%
  janitor::clean_names(.) %>% 
  select(-x15, -x16) %>% 
  mutate(sports_balls = as.integer(sports_balls), trash_program = "mr trash wheel") %>% 
  filter(!is.na(dumpster))
```

    ## New names:
    ## • `` -> `...15`
    ## • `` -> `...16`

## 2.2 Professor Trash Wheel Data: Read, Clean, Mutate, Filter

Using a similar approach applied in part 2.1, we will read and clean the
Professor Trash Wheel data, which is also contained within the Trash
Wheel Collection Data Excel spreadsheet. The same `trash_program`
variable was created and added to the data frame in preparation for
merging in further steps of Problem 2.

``` r
professor_trash_wheel = 
  read_excel("Trash Wheel Collection Data.xlsx", col_names = TRUE, sheet = 2, skip = 1) %>%
  janitor::clean_names(.) %>%
  mutate(year = as.character(year), trash_program = "professor trash wheel") %>% 
  filter(!is.na(dumpster))
```

## 2.3 Joining Mr. & Professor Trash Wheel Data

We proceed to combine the Mr. Trash Wheel and Professor Trash Wheel data
using the `bind_rows` function.

``` r
tidy_trash_wheel = bind_rows(mr_trash_wheel, professor_trash_wheel)
```

## 2.4 Analysis of Joint Trash Wheel Data

-   
-   
-   
-   
-   
-   
-   

### Total Weight of Trash & Sports Balls Collected

We can determine the total weight of trash collected by Professor Trash
Wheel by using the `sum` function, and specifying for the function be
applied to the `weight_tons` variable for entries corresponding to the
Professor Trash Wheel program.

``` r
sum(tidy_trash_wheel$weight_tons[tidy_trash_wheel$trash_program == "professor trash wheel"], na.rm = TRUE)
```

    ## [1] 190.12

The total weight of trash collection by Professor Trash Wheel is
**190.12 tonnes**.

Using a similar approach, we can determine the total number of sports
balls collected by Mr. Trash Wheel in 2020, by applying the `sum`
function with specific conditions.

``` r
sum(tidy_trash_wheel$sports_balls[tidy_trash_wheel$trash_program == "mr trash wheel" & tidy_trash_wheel$year == "2020"], na.rm = TRUE)
```

    ## [1] 856

Mr. Trash Wheel collected a total of **856 sports balls** in 2020.

# Problem 3

## 3.1 National Politicians Data: Read, Clean, Select, Mutate

First, we will read and clean the “Pols-Month” CSV file. This process
involves data importing, cleaning variable names, and separating the
`mon` variable into `year`, `month` and `day` variables. The newly
created `month` variable was recoded to have a month name instead of
number. Select variables were also removed as directed. A new
`president` variable was created, whose value depends on the values of
the `prez_gop` and `prez_dem` variables.

``` r
national_politicians = 
  read.csv("./pols-month.csv") %>% 
  janitor::clean_names(.) %>% 
  separate(col = mon, into = c('year', 'month','day'), sep = '-') %>%
  mutate(month = recode(month,
                        '01' = "January",
                        '02' = "February",
                        '03' = "March",
                        '04' = "April",
                        '05' = "May",
                        '06' = "June",
                        '07' = "July",
                        '08' = "August",
                        '09' = "September",
                        '10' = "October",
                        '11' = "November",
                        '12' = "December"), 
         president = ifelse(prez_gop == 1, "gop", ifelse(prez_dem == 1, "dem", NA))) %>%
  select(-prez_gop, -prez_dem, -day)
```

The code book provided for the “Pols-Month” data indicates that the
`prez_gop` variable should only take on the values of 1 = Yes and 0 =
No; however, it was discovered during the data wrangling process that
the `prez_gop` variable occasionally takes on the value of 2. As the
value of 2 was not coded in this case, and it is inappropriate to make
assumptions about the given data, the `president` variable was set to NA
for rows where `prez_gop = 2`. In this case, it would be important to
communicate with those who collected the data to clarify this
information.

## 3.2 SNP Data: Read, Clean, Select, Mutate

Second, we will read and clean the “SNP” CSV file, using a similar
approach used above. The `month` variable in the SNP data was recoded
such that the labeling is consistent with the `national_politicians`
data frame. The data is arranged to display the `year` and `month`
variables first.

``` r
snp_closing_value = 
  read.csv("./snp.csv") %>% 
  janitor::clean_names(.) %>%
  mutate(
    date = as.Date(date, "%m/%d/%y"),
    date = ifelse(date > "2015-07-01", format(date, "19%y-%m-%d"), format(date))
  ) %>% 
  separate(col = date, into = c('year', 'month','day'), sep = '-') %>%
  mutate(month = recode(month,
                        '01' = "January",
                        '02' = "February",
                        '03' = "March",
                        '04' = "April",
                        '05' = "May",
                        '06' = "June",
                        '07' = "July",
                        '08' = "August",
                        '09' = "September",
                        '10' = "October",
                        '11' = "November",
                        '12' = "December")) %>%  
  arrange(year, month) %>% 
  select(-day)
```

## 3.3 Unemployment Data: Read, Clean, Select, Mutate

Third, we will read and clean the “Unemployment” CSV file, using a
similar approach used above. The `pivot_longer` function was applied to
conver the data from wide to long format, collapsing each existing month
variable as distinct entries of a new `month` variable. This newly
created `month` variable was, again, recoded such that the labeling is
consistent with the `national_politicians` and `snp_closing_value` data
frames.

``` r
unemployment = 
  read.csv("./unemployment.csv") %>% 
  janitor::clean_names(.) %>% 
  pivot_longer(
    jan:dec,
    names_to = "month",
    values_to = "percent_unemployment") %>% 
  mutate(year = as.character(year),
         month = recode(month,
                        'jan' = "January",
                        'feb' = "February",
                        'mar' = "March",
                        'apr' = "April",
                        'may' = "May",
                        'jun' = "June",
                        'jul' = "July",
                        'aug' = "August",
                        'sep' = "September",
                        'oct' = "October",
                        'nov' = "November",
                        'dec' = "December"))
```

## 3.4 Joining Politician, SNP, Unemployment Data

Finally, we can merge the `national_politicians` and `snp_closing_value`
data frames created above, and merge the `unemployment` data frame to
the result of that first merge.

``` r
tidy_pol_snp = left_join(national_politicians, snp_closing_value, by = c("year","month"))
tidy_pol_snp_unemp = left_join(tidy_pol_snp, unemployment, by = c("year", "month"))
```

## 3.5 Analysis of Joint Politician, SNP, Unemployment Data

The first set of data imported in part 3.1, `national_politicians`,
contained **822 rows** (i.e., entries) and **9 columns** (i.e.,
variables), not including `year` and `month`. This data set contained
the numbers of democratic and republican governors (`gov_gop`,
`gov_dem`), senators (`sen_gop`, `sen_dem`), and representatives
(`rep_gop`, `rep_dem`) on a given date, as well as the political party
of the president on a given date (`president`). The years in this data
set ranged from **1947 to 2015**.

The second set of data imported in part 3.2, `snp_closing_value`,
contained **787 rows** (i.e., entries) and **3 columns** (i.e.,
variables), not including `year` and `month`. This data set contained
the closing values (`close`) of the S&P stock index on a given date. The
years in this data set ranged from **1950 to 2015**.

The third set of data imported in part 3.3, `unemployment`, contained
**816 rows** (i.e., entries) and **3 columns** (i.e., variables), not
including `year` and `month`. This data set contains the unemployment
rate (`percent_unemployment`) reported in percentages in a given month
of a given year. The years in this data set also ranged from **1950 to
2015**.

We can apply the `skimr` function, contained within the `skimr` library
to generate a summary of the merged `tidy_pol_snp_unemp` data set.

``` r
skimr::skim(tidy_pol_snp_unemp)
```

|                                                  |                    |
|:-------------------------------------------------|:-------------------|
| Name                                             | tidy_pol_snp_unemp |
| Number of rows                                   | 822                |
| Number of columns                                | 11                 |
| \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_   |                    |
| Column type frequency:                           |                    |
| character                                        | 3                  |
| numeric                                          | 8                  |
| \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ |                    |
| Group variables                                  | None               |

Data summary

**Variable type: character**

| skim_variable | n_missing | complete_rate | min | max | empty | n_unique | whitespace |
|:--------------|----------:|--------------:|----:|----:|------:|---------:|-----------:|
| year          |         0 |          1.00 |   4 |   4 |     0 |       69 |          0 |
| month         |         0 |          1.00 |   3 |   9 |     0 |       12 |          0 |
| president     |         5 |          0.99 |   3 |   3 |     0 |        2 |          0 |

**Variable type: numeric**

| skim_variable        | n_missing | complete_rate |   mean |     sd |     p0 |    p25 |    p50 |    p75 |    p100 | hist  |
|:---------------------|----------:|--------------:|-------:|-------:|-------:|-------:|-------:|-------:|--------:|:------|
| gov_gop              |         0 |          1.00 |  22.48 |   5.68 |  12.00 |  18.00 |  22.00 |  28.00 |   34.00 | ▆▆▇▅▅ |
| sen_gop              |         0 |          1.00 |  46.10 |   6.38 |  32.00 |  42.00 |  46.00 |  51.00 |   56.00 | ▃▃▇▇▇ |
| rep_gop              |         0 |          1.00 | 194.92 |  29.24 | 141.00 | 176.00 | 195.00 | 222.00 |  253.00 | ▃▇▆▃▅ |
| gov_dem              |         0 |          1.00 |  27.20 |   5.94 |  17.00 |  22.00 |  28.00 |  32.00 |   41.00 | ▆▅▇▆▂ |
| sen_dem              |         0 |          1.00 |  54.41 |   7.37 |  44.00 |  48.00 |  53.00 |  58.00 |   71.00 | ▇▆▇▃▂ |
| rep_dem              |         0 |          1.00 | 244.97 |  31.37 | 188.00 | 211.00 | 250.00 | 268.00 |  301.00 | ▇▂▇▇▅ |
| close                |        36 |          0.96 | 472.85 | 543.29 |  17.05 |  83.67 | 137.26 | 932.06 | 2107.39 | ▇▁▂▁▁ |
| percent_unemployment |        12 |          0.99 |   5.83 |   1.65 |   2.50 |   4.70 |   5.60 |   6.90 |   10.80 | ▃▇▅▂▁ |

This difference in year range compared to `national_politicians` data
set explains the missing values of variable `close` in the final merged
`tidy_pol_snp_unemp` data set.
