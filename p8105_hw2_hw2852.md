P8105 Data Science I Homework 2
================
Olivia Wang (hw2852)
2022-10-05

# Problem 1

In preparation for the problems below, we will load in the following
libraries: `tidyverse`, `dplyr`, and `readxl`.

``` r
library(tidyverse)
```

    ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──
    ## ✔ ggplot2 3.3.6      ✔ purrr   0.3.4 
    ## ✔ tibble  3.1.8      ✔ dplyr   1.0.10
    ## ✔ tidyr   1.2.0      ✔ stringr 1.4.1 
    ## ✔ readr   2.1.2      ✔ forcats 0.5.2 
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()

``` r
library(dplyr)
library(readxl)
```

## 1.1 Read, Clean, Select, Mutate Transit Data

We will begin by importing and cleaning the CSV file containing the NYC
Transit data. This process involves data import, cleaning variable
names, and retaining prescribed columns needed for further analysis. The
`entry` variable in the data set will be converted from a character to
logical vector, and `Route` columns 8 through 11 will be converted from
a numeric to character variable to achieve consistency with Routes 1
through 7.

``` r
transit_data = 
  read_csv("./NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names(.) %>% 
  select(., line, station_name, station_latitude, station_longitude, starts_with("route"), entry, vending, entrance_type, ada) %>% 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

    ## Rows: 1868 Columns: 32
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (22): Division, Line, Station Name, Route1, Route2, Route3, Route4, Rout...
    ## dbl  (8): Station Latitude, Station Longitude, Route8, Route9, Route10, Rout...
    ## lgl  (2): ADA, Free Crossover
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

-   Line
-   Station
-   Name
-   Station Latitude
-   Station Longitude
-   Routes Served
-   Entry
-   Vending
-   Entrance Type
-   ADA Compliance

Let us now generate a summary of the `transit_data` data set, and
determine the number of rows and columns in this data set.

``` r
summary(transit_data)
```

    ##      line           station_name       station_latitude station_longitude
    ##  Length:1868        Length:1868        Min.   :40.58    Min.   :-74.03   
    ##  Class :character   Class :character   1st Qu.:40.69    1st Qu.:-73.99   
    ##  Mode  :character   Mode  :character   Median :40.73    Median :-73.96   
    ##                                        Mean   :40.73    Mean   :-73.94   
    ##                                        3rd Qu.:40.77    3rd Qu.:-73.91   
    ##                                        Max.   :40.90    Max.   :-73.76   
    ##                                                                          
    ##     route1             route2             route3             route4         
    ##  Length:1868        Length:1868        Length:1868        Length:1868       
    ##  Class :character   Class :character   Class :character   Class :character  
    ##  Mode  :character   Mode  :character   Mode  :character   Mode  :character  
    ##                                                                             
    ##                                                                             
    ##                                                                             
    ##                                                                             
    ##     route5             route6             route7              route8     
    ##  Length:1868        Length:1868        Length:1868        Min.   :1.000  
    ##  Class :character   Class :character   Class :character   1st Qu.:1.000  
    ##  Mode  :character   Mode  :character   Mode  :character   Median :4.000  
    ##                                                           Mean   :2.979  
    ##                                                           3rd Qu.:5.000  
    ##                                                           Max.   :5.000  
    ##                                                           NA's   :1820   
    ##      route9         route10        route11       entry        
    ##  Min.   :2.000   Min.   :3      Min.   :7      Mode :logical  
    ##  1st Qu.:2.000   1st Qu.:3      1st Qu.:7      FALSE:115      
    ##  Median :2.000   Median :3      Median :7      TRUE :1753     
    ##  Mean   :2.536   Mean   :3      Mean   :7                     
    ##  3rd Qu.:2.000   3rd Qu.:3      3rd Qu.:7                     
    ##  Max.   :5.000   Max.   :3      Max.   :7                     
    ##  NA's   :1840    NA's   :1845   NA's   :1845                  
    ##    vending          entrance_type         ada         
    ##  Length:1868        Length:1868        Mode :logical  
    ##  Class :character   Class :character   FALSE:1400     
    ##  Mode  :character   Mode  :character   TRUE :468      
    ##                                                       
    ##                                                       
    ##                                                       
    ## 

``` r
nrow(transit_data)
```

    ## [1] 1868

``` r
ncol(transit_data)
```

    ## [1] 19

The newly created `transit_data` data set contains **1868 rows** and
**19 columns**.So far, we have loaded in the CSV data set containing NYC
Transit data. We then applied the `clean_names` function to clean up
variable names. The `select` function was applied to retain the
prescribed 19 variables. The `entry` variable was then converted from a
character variable (YES vs. NO) to a logical variable (TRUE vs. FALSE).
This tidied data set can now be used for further analysis.

## 1.2 Analyzing Transit Data

### 1.2.1 Enumerating Distinct Stations

To determine the number of distinct stations, the `distinct` function
can be applied. To do so, we must first load in the `dplyr` package that
contains the function.

``` r
library(dplyr)
distinct(transit_data, line, station_name, .keep_all = TRUE)
```

    ## # A tibble: 465 × 19
    ##    line     station_…¹ stati…² stati…³ route1 route2 route3 route4 route5 route6
    ##    <chr>    <chr>        <dbl>   <dbl> <chr>  <chr>  <chr>  <chr>  <chr>  <chr> 
    ##  1 4 Avenue 25th St       40.7   -74.0 R      <NA>   <NA>   <NA>   <NA>   <NA>  
    ##  2 4 Avenue 36th St       40.7   -74.0 N      R      <NA>   <NA>   <NA>   <NA>  
    ##  3 4 Avenue 45th St       40.6   -74.0 R      <NA>   <NA>   <NA>   <NA>   <NA>  
    ##  4 4 Avenue 53rd St       40.6   -74.0 R      <NA>   <NA>   <NA>   <NA>   <NA>  
    ##  5 4 Avenue 59th St       40.6   -74.0 N      R      <NA>   <NA>   <NA>   <NA>  
    ##  6 4 Avenue 77th St       40.6   -74.0 R      <NA>   <NA>   <NA>   <NA>   <NA>  
    ##  7 4 Avenue 86th St       40.6   -74.0 R      <NA>   <NA>   <NA>   <NA>   <NA>  
    ##  8 4 Avenue 95th St       40.6   -74.0 R      <NA>   <NA>   <NA>   <NA>   <NA>  
    ##  9 4 Avenue 9th St        40.7   -74.0 F      G      R      <NA>   <NA>   <NA>  
    ## 10 4 Avenue Atlantic …    40.7   -74.0 B      Q      D      N      R      2     
    ## # … with 455 more rows, 9 more variables: route7 <chr>, route8 <dbl>,
    ## #   route9 <dbl>, route10 <dbl>, route11 <dbl>, entry <lgl>, vending <chr>,
    ## #   entrance_type <chr>, ada <lgl>, and abbreviated variable names
    ## #   ¹​station_name, ²​station_latitude, ³​station_longitude

Based on the output generated from the code above, we can conclude that
there are **465** distinct stations.

### 1.2.2 Enumerating ADA-Compliant Stations

To determine the number of stations that are ADA compliant, we can apply
the `count` function to, as the name suggests, count the number of
entries for the `ada` variable are “TRUE”.

``` r
count(transit_data, ada)
```

    ## # A tibble: 2 × 2
    ##   ada       n
    ##   <lgl> <int>
    ## 1 FALSE  1400
    ## 2 TRUE    468

Based on the output generated from the code above, we can conclude that
there are **468** ADA-compliant stations.

### 1.2.3 Proportion of Station Entrances & Exits Without Vending Allow Entry

To determine the proportion of station entrances and exits without
vending that allow entry, we can create the following two variables:
`no_vending_total`, representing the total number of station entrances
and exits that do not have vending; and `no_vending_yes_entry`,
representing the total number of station entrances and exits that do not
have vending, but also allow entry. We can then divide the value of
`no_vending_yes_entry` by that of `no_vending_total` to get a final
proportion.

``` r
no_vending_total = nrow(transit_data[transit_data$vending == 'NO', ])
no_vending_yes_entry = nrow(transit_data[which(transit_data$vending == 'NO' & transit_data$entry == TRUE), ])
no_vending_yes_entry / no_vending_total
```

    ## [1] 0.3770492

Based on the output generated from the code above, we can conclude that
about **37.7%** of station entrances and exists without vending allow
entry.

### 1.2.4

# Problem 2

``` r
mr_trash_wheel = 
  read_excel("Trash Wheel Collection Data.xlsx", col_names = TRUE, sheet = 1, skip = 1) %>%
  janitor::clean_names(.) %>% 
  select(-x15, -x16) %>% 
  mutate(sports_balls = as.integer(sports_balls), trash_program = "mr trash wheel") %>% 
  filter(!is.na(dumpster))
```

    ## New names:
    ## • `` -> `...15`
    ## • `` -> `...16`

Next, let us read and clean the Professor Trash Wheel Excel spreadsheet.

``` r
professor_trash_wheel = 
  read_excel("Trash Wheel Collection Data.xlsx", col_names = TRUE, sheet = 2, skip = 1) %>%
  janitor::clean_names(.) %>%
  mutate(year = as.character(year), trash_program = "professor trash wheel") %>% 
  filter(!is.na(dumpster))
```

We proceed to combine the Mr. Trash Wheel and Professor Trash Wheel
datasets using `bind_rows`.

``` r
tidy_trash_wheel = bind_rows(mr_trash_wheel, professor_trash_wheel)
```

``` r
nrow(tidy_trash_wheel)
```

    ## [1] 641

``` r
sum(tidy_trash_wheel$weight_tons[tidy_trash_wheel$trash_program == "professor trash wheel"], na.rm = TRUE)
```

    ## [1] 190.12

``` r
sum(tidy_trash_wheel$sports_balls[tidy_trash_wheel$trash_program == "mr trash wheel" & tidy_trash_wheel$year == "2020"], na.rm = TRUE)
```

    ## [1] 856

# Problem 3

First, we will read and clean the `pols-month.csv` file.

``` r
national_politicians = 
  read.csv("./pols-month.csv") %>% 
  janitor::clean_names(.) %>% 
  separate(col = mon, into = c('year', 'month','day'), sep = '-') %>%
  mutate(month = recode(month,
                        '01' = "January",
                        '02' = "February",
                        '03' = "March",
                        '04' = "April",
                        '05' = "May",
                        '06' = "June",
                        '07' = "July",
                        '08' = "August",
                        '09' = "September",
                        '10' = "October",
                        '11' = "November",
                        '12' = "December"), 
         president = ifelse(prez_gop == 1, "gop", ifelse(prez_dem == 1, "dem", NA))) %>%
  select(-prez_gop, -prez_dem, -day)
```

\*\*Note sometimes prez+gop is equal to 2?

Next, we will read and clean the `snp.cvs` file.

``` r
snp_closing_value = 
  read.csv("./snp.csv") %>% 
  janitor::clean_names(.) %>%
  mutate(
    date = as.Date(date, "%m/%d/%y"),
    date = ifelse(date > "2015-07-01", format(date, "19%y-%m-%d"), format(date))
  ) %>% 
  separate(col = date, into = c('year', 'month','day'), sep = '-') %>%
  mutate(month = recode(month,
                        '01' = "January",
                        '02' = "February",
                        '03' = "March",
                        '04' = "April",
                        '05' = "May",
                        '06' = "June",
                        '07' = "July",
                        '08' = "August",
                        '09' = "September",
                        '10' = "October",
                        '11' = "November",
                        '12' = "December")) %>%  
  select(-day)
```

We will now read and clean the `unemployment.csv` file.

``` r
unemployment = 
  read.csv("./unemployment.csv") %>% 
  janitor::clean_names(.) %>% 
  pivot_longer(
    jan:dec,
    names_to = "month",
    values_to = "percent_unemployment") %>% 
  mutate(year = as.character(year),
         month = recode(month,
                        'jan' = "January",
                        'feb' = "February",
                        'mar' = "March",
                        'apr' = "April",
                        'may' = "May",
                        'jun' = "June",
                        'jul' = "July",
                        'aug' = "August",
                        'sep' = "September",
                        'oct' = "October",
                        'nov' = "November",
                        'dec' = "December"))
```

Finally, we can merge the `national_politicians` and `snp_closing_value`
data frames created above, and merge the `unemployment` data frame to
the result.

``` r
tidy_pol_snp = left_join(national_politicians, snp_closing_value, by = c("year","month"))
tidy_pol_snp_unemp = left_join(tidy_pol_snp, unemployment, by = c("year", "month"))
```
