---
title: "P8105 Data Science I Homework 2"
author: Olivia Wang (hw2852)
output: github_document
date: "2022-10-05"
---

# Problem 1 

In preparation for the problems below, we will load in the following libraries: `tidyverse`, `dplyr`, and `readxl`.
```{r load_libraries}
library(tidyverse)
library(dplyr)
library(readxl)
```

## 1.1 Read, Clean, Select, Mutate Transit Data

We will begin by importing and cleaning the CSV file containing the NYC Transit data. This process involves data import, cleaning variable names, and retaining prescribed columns needed for further analysis. The `entry` variable in the data set will be converted from a character to logical vector, and `Route` columns 8 through 11 will be converted from a numeric to character variable to achieve consistency with Routes 1 through 7. 

```{r}
transit_data = 
  read_csv("./NYC_Transit_Subway_Entrance_And_Exit_Data.csv", 
             col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) %>% 
  janitor::clean_names(.) %>% 
  select(line, station_name, station_latitude, station_longitude, starts_with("route"), entry, exit_only, vending, entrance_type, ada) %>% 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

These data are not entirely tidy as they are shown, since there are additional improvements that can be made. For example, we may apply the `pivot_longer` function to convert the data from wide to long format by collapsing the existing variables starting with `route`. We can then create new `route number` and `route` variables, populated with relevant information. 

## 1.2 Analyzing Transit Data

### Unique Stations

Next, Using the `distint` function, we can identify the unique combinations of `station_name` and `line` variable values. The number of rows generated in the output would be the number of _unique_ stations in the data set. 

```{r}
transit_data %>% 
  select(station_name, line) %>% 
  distinct
```

There are __465__ unique stations in the data set. 

### Unique ADA-Compliant Stations

Using a similar approach applied to determining the number of distinct stations, we can apply the `distinct` function again to determine the number of _unique_ ADA-compliant stations. We first begin by filtering the `transit_data` data frame to only include ADA-compliant stations. The number of rows generated in the output is the number of _unique_ ADA-compliant stations in the data set. 

```{r}
transit_data %>% 
  filter(ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```
There are __84__ unique ADA-compliant stations in the data set. 

### Proportion of Entrances/Exits Without Vending that Allow Entrance

To determine the proportion of entrances and exits without vending that allow entrance, we can first apply the `filter` function to exclude station entrances without vending. Next, we can take the mean of the `entry` variable to generate the desired proportion. Recall that in part 1.1, the `entry` variable was converted from a character to logical variable. R is able to coerce logical to numeric variables for these types of arithmetic calculations. 

```{r}
transit_data %>% 
  filter(vending == "NO") %>% 
  pull(entry) %>% 
  mean
```
About __37.7%__ of station entrances/exits without vending allow entrance. 

### Unique Stations Serving the A Train

We can first further tidy the data using the aforementioned method in part 1.1, specifically using the `pivot_longer` function to convert the `route` variable from wide to long format. We can apply similar functions, specifically the `filter`, `select`, and `distinct` functions to focus specifically on A train service, then identify unique stations. The number of rows generated in the output is the number of unique stations that serve the A train in the data set. 

```{r}
transit_data %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_number",
    values_to = "route") %>% 
  filter(route == "A") %>% 
  select(station_name, line) %>% 
  distinct
```
There are __60__ unique stations that serve the A train. 

### Unique ADA-Compliant Stations Serving the A Train 

Using the exact same methodology as above, we can determine the number of unique ADA-compliant stations that serve the A train by filtering both by A train service, as well as ADA-compliance. The number of rows generated in the output is the number of unique ADA-compliant stations that serve the A train in the data set. 

```{r}
transit_data %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_number",
    values_to = "route") %>% 
  filter(route == "A", ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```
There are __17__ unique ADA-compliant stations that serve the A train. 

# Problem 2


```{r}
mr_trash_wheel = 
  read_excel("Trash Wheel Collection Data.xlsx", col_names = TRUE, sheet = 1, skip = 1) %>%
  janitor::clean_names(.) %>% 
  select(-x15, -x16) %>% 
  mutate(sports_balls = as.integer(sports_balls), trash_program = "mr trash wheel") %>% 
  filter(!is.na(dumpster))
```

Next, let us read and clean the Professor Trash Wheel Excel spreadsheet. 
```{r}
professor_trash_wheel = 
  read_excel("Trash Wheel Collection Data.xlsx", col_names = TRUE, sheet = 2, skip = 1) %>%
  janitor::clean_names(.) %>%
  mutate(year = as.character(year), trash_program = "professor trash wheel") %>% 
  filter(!is.na(dumpster))
```

We proceed to combine the Mr. Trash Wheel and Professor Trash Wheel datasets using `bind_rows`.

```{r}
tidy_trash_wheel = bind_rows(mr_trash_wheel, professor_trash_wheel)
```

```{r}
nrow(tidy_trash_wheel)
```
```{r}
sum(tidy_trash_wheel$weight_tons[tidy_trash_wheel$trash_program == "professor trash wheel"], na.rm = TRUE)
```

```{r}
sum(tidy_trash_wheel$sports_balls[tidy_trash_wheel$trash_program == "mr trash wheel" & tidy_trash_wheel$year == "2020"], na.rm = TRUE)
```

# Problem 3

First, we will read and clean the `pols-month.csv` file. 
```{r}
national_politicians = 
  read.csv("./pols-month.csv") %>% 
  janitor::clean_names(.) %>% 
  separate(col = mon, into = c('year', 'month','day'), sep = '-') %>%
  mutate(month = recode(month,
                        '01' = "January",
                        '02' = "February",
                        '03' = "March",
                        '04' = "April",
                        '05' = "May",
                        '06' = "June",
                        '07' = "July",
                        '08' = "August",
                        '09' = "September",
                        '10' = "October",
                        '11' = "November",
                        '12' = "December"), 
         president = ifelse(prez_gop == 1, "gop", ifelse(prez_dem == 1, "dem", NA))) %>%
  select(-prez_gop, -prez_dem, -day)
```

**Note sometimes prez+gop is equal to 2?

Next, we will read and clean the `snp.cvs` file. 
```{r}
snp_closing_value = 
  read.csv("./snp.csv") %>% 
  janitor::clean_names(.) %>%
  mutate(
    date = as.Date(date, "%m/%d/%y"),
    date = ifelse(date > "2015-07-01", format(date, "19%y-%m-%d"), format(date))
  ) %>% 
  separate(col = date, into = c('year', 'month','day'), sep = '-') %>%
  mutate(month = recode(month,
                        '01' = "January",
                        '02' = "February",
                        '03' = "March",
                        '04' = "April",
                        '05' = "May",
                        '06' = "June",
                        '07' = "July",
                        '08' = "August",
                        '09' = "September",
                        '10' = "October",
                        '11' = "November",
                        '12' = "December")) %>%  
  select(-day)
```

We will now read and clean the `unemployment.csv` file. 
```{r}
unemployment = 
  read.csv("./unemployment.csv") %>% 
  janitor::clean_names(.) %>% 
  pivot_longer(
    jan:dec,
    names_to = "month",
    values_to = "percent_unemployment") %>% 
  mutate(year = as.character(year),
         month = recode(month,
                        'jan' = "January",
                        'feb' = "February",
                        'mar' = "March",
                        'apr' = "April",
                        'may' = "May",
                        'jun' = "June",
                        'jul' = "July",
                        'aug' = "August",
                        'sep' = "September",
                        'oct' = "October",
                        'nov' = "November",
                        'dec' = "December"))
```

Finally, we can merge the `national_politicians` and `snp_closing_value` data frames created above, and merge the `unemployment` data frame to the result. 
```{r}
tidy_pol_snp = left_join(national_politicians, snp_closing_value, by = c("year","month"))
tidy_pol_snp_unemp = left_join(tidy_pol_snp, unemployment, by = c("year", "month"))
```

