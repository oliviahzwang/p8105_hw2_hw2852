---
title: "P8105 Data Science I Homework 2"
author: Olivia Wang (hw2852)
output: github_document
date: "2022-10-05"
---

# Problem 1 

In preparation for the problems below, we will load in the following libraries: `tidyverse`, `dplyr`, and `readxl`. 
```{r load_libraries}
library(tidyverse)
library(dplyr)
library(readxl)
```

## 1.1 Transit Data: Read, Clean, Select, Mutate 

We will begin by importing and cleaning the CSV file containing the NYC Transit data. This process involves data import, cleaning variable names, and retaining prescribed columns needed for further analysis. The `entry` variable in the data set will be converted from a character to logical vector, and `Route` columns 8 through 11 will be converted from a numeric to character variable to achieve consistency with Routes 1 through 7. 

```{r}
transit_data = 
  read_csv("./NYC_Transit_Subway_Entrance_And_Exit_Data.csv", 
             col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) %>% 
  janitor::clean_names(.) %>% 
  select(line, station_name, station_latitude, station_longitude, starts_with("route"), entry, exit_only, vending, entrance_type, ada) %>% 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

These data are not entirely tidy as they are shown, since there are additional improvements that can be made. For example, we may apply the `pivot_longer` function to convert the data from wide to long format by collapsing the existing variables starting with `route`. We can then create new `route number` and `route` variables, populated with relevant information. 

## 1.2 Analyzing Transit Data

### Unique Stations

Next, Using the `distint` function, we can identify the unique combinations of `station_name` and `line` variable values. The number of rows generated in the output would be the number of _unique_ stations in the data set. 

```{r}
transit_data %>% 
  select(station_name, line) %>% 
  distinct
```

There are __465__ unique stations in the data set. 

### Unique ADA-Compliant Stations

Using a similar approach applied to determining the number of distinct stations, we can apply the `distinct` function again to determine the number of _unique_ ADA-compliant stations. We first begin by filtering the `transit_data` data frame to only include ADA-compliant stations. The number of rows generated in the output is the number of _unique_ ADA-compliant stations in the data set. 

```{r}
transit_data %>% 
  filter(ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```
There are __84__ unique ADA-compliant stations in the data set. 

### Proportion of Entrances/Exits Without Vending that Allow Entrance

To determine the proportion of entrances and exits without vending that allow entrance, we can first apply the `filter` function to exclude station entrances without vending. Next, we can take the mean of the `entry` variable to generate the desired proportion. Recall that in part 1.1, the `entry` variable was converted from a character to logical variable. R is able to coerce logical to numeric variables for these types of arithmetic calculations. 

```{r}
transit_data %>% 
  filter(vending == "NO") %>% 
  pull(entry) %>% 
  mean
```
About __37.7%__ of station entrances/exits without vending allow entrance. 

### Unique Stations Serving the A Train

We can first further tidy the data using the aforementioned method in part 1.1, specifically using the `pivot_longer` function to convert the `route` variable from wide to long format. We can apply similar functions, specifically the `filter`, `select`, and `distinct` functions to focus specifically on A train service, then identify unique stations. The number of rows generated in the output is the number of unique stations that serve the A train in the data set. 

```{r}
transit_data %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_number",
    values_to = "route") %>% 
  filter(route == "A") %>% 
  select(station_name, line) %>% 
  distinct
```
There are __60__ unique stations that serve the A train. 

### Unique ADA-Compliant Stations Serving the A Train 

Using the exact same methodology as above, we can determine the number of unique ADA-compliant stations that serve the A train by filtering both by A train service, as well as ADA-compliance. The number of rows generated in the output is the number of unique ADA-compliant stations that serve the A train in the data set. 

```{r}
transit_data %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_number",
    values_to = "route") %>% 
  filter(route == "A", ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```
There are __17__ unique ADA-compliant stations that serve the A train. 

# Problem 2

## 2.1 Mr. Trash Wheel Data: Read, Clean, Select, Mutate 

First, let us read and clean the Mr. Trash Wheel data set, contained within the Trash Wheel Collection Data Excel spreadsheet. This process involves data import using the `read_excel` function contained within the `readxl` library, cleaning variable names, exclusion rows with non-dumpster-specific data, and rounding of the `sports_balls` variable to the nearest whole number. An additional variable `trash_program` was created and added to the data frame in preparation for merging in further steps of Problem 2. 

```{r}
mr_trash_wheel = 
  read_excel("Trash Wheel Collection Data.xlsx", col_names = TRUE, sheet = 1, skip = 1) %>%
  janitor::clean_names(.) %>% 
  select(-x15, -x16) %>% 
  mutate(sports_balls = as.integer(sports_balls), trash_program = "mr trash wheel") %>% 
  filter(!is.na(dumpster))
```
## 2.2 Professor Trash Wheel Data: Read, Clean, Mutate, Filter

Using a similar approach applied in part 2.1, we will read and clean the Professor Trash Wheel data, which is also contained within the Trash Wheel Collection Data Excel spreadsheet. The same `trash_program` variable was created and added to the data frame in preparation for merging in further steps of Problem 2. 

```{r}
professor_trash_wheel = 
  read_excel("Trash Wheel Collection Data.xlsx", col_names = TRUE, sheet = 2, skip = 1) %>%
  janitor::clean_names(.) %>%
  mutate(year = as.character(year), trash_program = "professor trash wheel") %>% 
  filter(!is.na(dumpster))
```

## 2.3 Joining Mr. & Professor Trash Wheel Data

We proceed to combine the Mr. Trash Wheel and Professor Trash Wheel data using the `bind_rows` function.

```{r}
tidy_trash_wheel = bind_rows(mr_trash_wheel, professor_trash_wheel)
```

## 2.4 Analysis of Joint Trash Wheel Data

The `tidy_trash_wheel` data set contained __`r nrow(tidy_trash_wheel)` rows__ (i.e., entries) and __`r ncol(tidy_trash_wheel)` columns__ (i.e., variables). This data set contained information regarding amounts of different types of trash collected by the Mr. Trash Wheel and Professor Trash Wheel programs on a given date, including total weight in tonnes and volume in cubic yards, number of plastic bottles, polystyrene, cigarette butts, glass bottles, grocery bags, chip bags and sports balls. Collection data in this data set corresponded to years ranging from __2014 to 2022__. 

### Total Weight of Trash & Sports Balls Collected

We can determine the total weight of trash collected by Professor Trash Wheel by using the `sum` function, and specifying for the function be applied to the `weight_tons` variable for entries corresponding to the Professor Trash Wheel program. 

```{r}
sum(tidy_trash_wheel$weight_tons[tidy_trash_wheel$trash_program == "professor trash wheel"], na.rm = TRUE)
```

The total weight of trash collection by Professor Trash Wheel is __190.12 tonnes__. 

Using a similar approach, we can determine the total number of sports balls collected by Mr. Trash Wheel in 2020, by applying the `sum` function with specific conditions. 

```{r}
sum(tidy_trash_wheel$sports_balls[tidy_trash_wheel$trash_program == "mr trash wheel" & tidy_trash_wheel$year == "2020"], na.rm = TRUE)
```

Mr. Trash Wheel collected a total of __856 sports balls__ in 2020. 

# Problem 3

## 3.1 National Politicians Data: Read, Clean, Select, Mutate

First, we will read and clean the "Pols-Month" CSV file. This process involves data importing, cleaning variable names, and separating the `mon` variable into `year`, `month` and `day` variables. The newly created `month` variable was recoded to have a month name instead of number. Select variables were also removed as directed. A new `president` variable was created, whose value depends on the values of the `prez_gop` and `prez_dem` variables. 

```{r}
national_politicians = 
  read.csv("./pols-month.csv") %>% 
  janitor::clean_names(.) %>% 
  separate(col = mon, into = c('year', 'month','day'), sep = '-') %>%
  mutate(month = recode(month,
                        '01' = "January",
                        '02' = "February",
                        '03' = "March",
                        '04' = "April",
                        '05' = "May",
                        '06' = "June",
                        '07' = "July",
                        '08' = "August",
                        '09' = "September",
                        '10' = "October",
                        '11' = "November",
                        '12' = "December"), 
         president = ifelse(prez_gop == 1, "gop", ifelse(prez_dem == 1, "dem", NA))) %>%
  select(-prez_gop, -prez_dem, -day)
```

The code book provided for the "Pols-Month" data indicates that the `prez_gop` variable should only take on the values of 1 = Yes and 0 = No; however, it was discovered during the data wrangling process that the `prez_gop` variable occasionally takes on the value of 2. As the value of 2 was not coded in this case, and it is inappropriate to make assumptions about the given data, the `president` variable was set to NA for rows where `prez_gop = 2`. In this case, it would be important to communicate with those who collected the data to clarify this information. 

## 3.2 SNP Data: Read, Clean, Select, Mutate

Second, we will read and clean the "SNP" CSV file, using a similar approach used above. The `month` variable in the SNP data was recoded such that the labeling is consistent with the `national_politicians` data frame. The data is arranged to display the `year` and `month` variables first. 

```{r}
snp_closing_value = 
  read.csv("./snp.csv") %>% 
  janitor::clean_names(.) %>%
  mutate(
    date = as.Date(date, "%m/%d/%y"),
    date = ifelse(date > "2015-07-01", format(date, "19%y-%m-%d"), format(date))
  ) %>% 
  separate(col = date, into = c('year', 'month','day'), sep = '-') %>%
  mutate(month = recode(month,
                        '01' = "January",
                        '02' = "February",
                        '03' = "March",
                        '04' = "April",
                        '05' = "May",
                        '06' = "June",
                        '07' = "July",
                        '08' = "August",
                        '09' = "September",
                        '10' = "October",
                        '11' = "November",
                        '12' = "December")) %>%  
  arrange(year, month) %>% 
  select(-day)
```

## 3.3 Unemployment Data: Read, Clean, Select, Mutate

Third, we will read and clean the "Unemployment" CSV file, using a similar approach used above. The `pivot_longer` function was applied to conver the data from wide to long format, collapsing each existing month variable as distinct entries of a new `month` variable. This newly created `month` variable was, again, recoded such that the labeling is consistent with the `national_politicians` and `snp_closing_value` data frames. 

```{r}
unemployment = 
  read.csv("./unemployment.csv") %>% 
  janitor::clean_names(.) %>% 
  pivot_longer(
    jan:dec,
    names_to = "month",
    values_to = "percent_unemployment") %>% 
  mutate(year = as.character(year),
         month = recode(month,
                        'jan' = "January",
                        'feb' = "February",
                        'mar' = "March",
                        'apr' = "April",
                        'may' = "May",
                        'jun' = "June",
                        'jul' = "July",
                        'aug' = "August",
                        'sep' = "September",
                        'oct' = "October",
                        'nov' = "November",
                        'dec' = "December"))
```

## 3.4 Joining Politician, SNP, Unemployment Data

Finally, we can merge the `national_politicians` and `snp_closing_value` data frames created above, and merge the `unemployment` data frame to the result of that first merge. 

```{r}
tidy_pol_snp = left_join(national_politicians, snp_closing_value, by = c("year","month"))
tidy_pol_snp_unemp = left_join(tidy_pol_snp, unemployment, by = c("year", "month"))
```

## 3.5 Analysis of Joint Politician, SNP, Unemployment Data

The first set of data imported and cleaned in part 3.1, `national_politicians`, contained __`r nrow(national_politicians)` rows__ (i.e., entries) and __`r ncol(national_politicians)` columns__ (i.e., variables), not including `year` and `month`. This data set contained the numbers of democratic and republican governors (`gov_gop`, `gov_dem`), senators (`sen_gop`, `sen_dem`), and representatives (`rep_gop`, `rep_dem`) on a given date, as well as the political party of the president on a given date (`president`). The years in this data set ranged from __1947 to 2015__. 

The second set of data imported and cleaned in part 3.2, `snp_closing_value`, contained __`r nrow(snp_closing_value)` rows__ (i.e., entries) and __`r ncol(snp_closing_value)` columns__ (i.e., variables), not including `year` and `month`. This data set contained the  closing values (`close`) of the S&P stock index on a given date. The years in this data set ranged from __1950 to 2015__.

The third set of data imported and cleaned in part 3.3, `unemployment`, contained __`r nrow(unemployment)` rows__ (i.e., entries) and __`r ncol(unemployment)` columns__ (i.e., variables), not including `year` and `month`. This data set contains the unemployment rate (`percent_unemployment`) reported in percentages in a given month of a given year. The years in this data set ranged from __1948 to 2015__. 

We can apply the `skimr` function, contained within the `skimr` library to generate a summary of the merged `tidy_pol_snp_unemp` data set. 

```{r}
skimr::skim(tidy_pol_snp_unemp)
```

The resulting data set created in part 3.4, `tidy_pol_snp_unemp`, contained __`r nrow(tidy_pol_snp_unemp)` rows__ (i.e., entries) and __`r ncol(tidy_pol_snp_unemp)` columns__ (i.e., variables). The years in this data set contained the widest range from __1947 to 2015__. The difference noted in year range between the final merged data set and the  `snp_closing_value` and `unemployment` data sets explain the _36_ missing values of variable `close` and _12_ missing values of `percent_unemployment` in the final merged `tidy_pol_snp_unemp` data set. 
